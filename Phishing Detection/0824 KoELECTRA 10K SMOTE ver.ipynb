{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1k0wTLkhwAdA-VCndH6KwIZw_DzDEdw-4","authorship_tag":"ABX9TyMYDxQh/okydbFhftJdEF2B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install accelerate>=0.20.1\n","!pip install transformers[torch]\n","!pip install accelerate transformers[torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P06dWXjlt-0A","executionInfo":{"status":"ok","timestamp":1692862407609,"user_tz":-540,"elapsed":25696,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"3eb0de39-3bbb-488f-d0cb-c0e5c4f659e9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.32.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.32.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.utils import shuffle\n","\n","# 데이터 불러오기\n","label1_data = pd.read_csv(\"/content/drive/MyDrive/voise_antinoise_morphemes_refined_v3.csv\")\n","label0_data_1 = pd.read_csv(\"/content/drive/MyDrive/normalcall_original.csv\")\n","label0_data_2 = pd.read_csv(\"/content/drive/MyDrive/finaldataset/nofish.csv\")\n","label1_data[\"text\"] = label1_data[\"Translated_Sentence\"]\n","label1_data.drop(columns=['Translated_Sentence'], inplace=True)\n","label0_data_2[\"text\"] = label0_data_2[\"refined_text\"]\n","label0_data_2.drop(columns=['refined_text'], inplace=True)\n","\n","# 라벨 0 데이터 랜덤 추출\n","label0_data_1_sampled = label0_data_1.sample(n=2500, random_state=42)\n","label0_data_2_sampled = label0_data_2.sample(n=2500, random_state=42)\n","\n","# 라벨 부여\n","label1_data['label'] = 1\n","label0_data_1_sampled['label'] = 0\n","label0_data_2_sampled['label'] = 0\n","\n","# 데이터 병합\n","intergrated_unbalan2 = pd.concat([label1_data, label0_data_1_sampled, label0_data_2_sampled])\n","intergrated_unbalan2 = shuffle(intergrated_unbalan2, random_state=42).reset_index(drop=True)\n","\n","# 결과 확인\n","intergrated_unbalan2.head()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"5gY7xTATe7dM","executionInfo":{"status":"ok","timestamp":1692865494258,"user_tz":-540,"elapsed":1872,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"77a36f57-a80b-4b7b-e4c7-8d6e92727159"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0    안녕하세요 소속 상담원 이름입니다   승인 취소 내역을 확인하고 싶어요   네 ...      0\n","1    반갑습니다 소속 이름 입니다   네 저기 분당구 오리역에 에이에스 센터 전화번호...      0\n","2    안녕하세요 소속 이름 입니다   안녕하세요 문의 좀 드리려고 하는데요   네 말...      0\n","3    안녕하세요 무엇을 도와드릴까요   외국도서의 오디오북은 무엇인가요   시간 여유...      0\n","4  여보세요? 네 여보세요? 네? 네 안녕하세요 고위님 국민은행 김진아 - - - - ...      1"],"text/html":["\n","  <div id=\"df-249c02f7-e8ce-49cb-afe1-39311e5baf83\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>안녕하세요 소속 상담원 이름입니다   승인 취소 내역을 확인하고 싶어요   네 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>반갑습니다 소속 이름 입니다   네 저기 분당구 오리역에 에이에스 센터 전화번호...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>안녕하세요 소속 이름 입니다   안녕하세요 문의 좀 드리려고 하는데요   네 말...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>안녕하세요 무엇을 도와드릴까요   외국도서의 오디오북은 무엇인가요   시간 여유...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>여보세요? 네 여보세요? 네? 네 안녕하세요 고위님 국민은행 김진아 - - - - ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-249c02f7-e8ce-49cb-afe1-39311e5baf83')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-249c02f7-e8ce-49cb-afe1-39311e5baf83 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-249c02f7-e8ce-49cb-afe1-39311e5baf83');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c74b40e3-22ad-4a5e-8d32-d3277740f2ca\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c74b40e3-22ad-4a5e-8d32-d3277740f2ca')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c74b40e3-22ad-4a5e-8d32-d3277740f2ca button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import pandas as pd\n","import random\n","from itertools import combinations\n","\n","# 데이터 불러오기\n","label1_data = pd.read_csv(\"/content/drive/MyDrive/voise_antinoise_morphemes_refined_v3.csv\")\n","data = label1_data[\"Translated_Sentence\"].tolist()\n","\n","# 가능한 모든 조합을 생성합니다.\n","combinations_list = list(combinations(data, 2))\n","\n","# 생성된 개수를 출력하는 함수\n","def print_generated_count(count):\n","    if count % 1000 == 0:\n","        print(f\"{count}개 생성됨\")\n","\n","# 10,000개의 데이터를 생성합니다.\n","generated_data = []\n","while len(generated_data) < 10000:\n","    random_combination = random.choice(combinations_list)\n","    generated_text = \" \".join(random_combination)\n","    generated_data.append(generated_text)\n","    print_generated_count(len(generated_data))\n","\n","# 중복 제거 후 데이터 프레임 생성\n","df = pd.DataFrame(generated_data, columns=[\"combined_data\"])\n","df = df.drop_duplicates()\n","\n","# 데이터 프레임 형태 출력\n","print(df.shape)\n","\n","# CSV 파일로 저장\n","df.to_csv(\"generated_data.csv\", index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8gr4hzxAaYr","executionInfo":{"status":"ok","timestamp":1692871545041,"user_tz":-540,"elapsed":858,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"60fbd4e1-2530-455b-8cf3-ae27a664d043"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["1000개 생성됨\n","2000개 생성됨\n","3000개 생성됨\n","4000개 생성됨\n","5000개 생성됨\n","6000개 생성됨\n","7000개 생성됨\n","8000개 생성됨\n","9000개 생성됨\n","10000개 생성됨\n","(9980, 1)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.utils import shuffle\n","\n","# 데이터 불러오기\n","label1_data = pd.read_csv(\"generated_data.csv\")\n","label0_data_1 = pd.read_csv(\"/content/drive/MyDrive/normalcall_original.csv\")\n","label0_data_2 = pd.read_csv(\"/content/drive/MyDrive/finaldataset/nofish.csv\")\n","label1_data[\"text\"] = label1_data[\"combined_data\"]\n","label1_data.drop(columns=['combined_data'], inplace=True)\n","label0_data_2[\"text\"] = label0_data_2[\"refined_text\"]\n","label0_data_2.drop(columns=['refined_text'], inplace=True)\n","\n","# 라벨 0 데이터 랜덤 추출\n","label0_data_1_sampled = label0_data_1.sample(n=5010, random_state=42)\n","label0_data_2_sampled = label0_data_2.sample(n=5010, random_state=42)\n","\n","# 라벨 부여\n","label1_data['label'] = 1\n","label0_data_1_sampled['label'] = 0\n","label0_data_2_sampled['label'] = 0\n","\n","# 데이터 병합\n","intergrated_unbalan4 = pd.concat([label1_data, label0_data_1_sampled, label0_data_2_sampled])\n","intergrated_unbalan4 = shuffle(intergrated_unbalan4, random_state=42).reset_index(drop=True)"],"metadata":{"id":"g2oLWwNKAr5a","executionInfo":{"status":"ok","timestamp":1692872029112,"user_tz":-540,"elapsed":2761,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["intergrated_unbalan4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yr3ybD9VBill","executionInfo":{"status":"ok","timestamp":1692872812545,"user_tz":-540,"elapsed":8,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"9ff0a3a4-6e99-4bb5-9ae1-4fd72d488200"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20000 entries, 0 to 19999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   text    20000 non-null  object\n"," 1   label   20000 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 312.6+ KB\n"]}]},{"cell_type":"code","source":["# CSV 파일로 저장\n","intergrated_unbalan4.to_csv(\"/content/drive/MyDrive/intergrated_unbalan4.csv\", index=False)\n"],"metadata":{"id":"x0yeS-4DB1_H","executionInfo":{"status":"ok","timestamp":1692872419650,"user_tz":-540,"elapsed":750,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/MyDrive/intergrated_unbalan4.csv\")\n","data.head(30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":990},"id":"omss9O7jP_RD","executionInfo":{"status":"ok","timestamp":1692875634573,"user_tz":-540,"elapsed":1526,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"9320af43-c8e9-4f49-d88a-00029fa97dcb"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 text  label\n","0     반갑습니다 소속 상담사 이름입니다 무엇을 도와드릴까요   일주일 동안 계속 인터...      0\n","1   네 본인 혹시 에 거주하는 42세 남성 김춘철이라고 아시는 분이십니까? 아 모르는데...      1\n","2   걱정 안 하셔도 되고 신용등급 하락이라는 건 14일 이내에 채무 계약 처리로 상황처...      1\n","3   아 예 수고하십니다. 서울지검 김수사관이에요. 지금 통화 좀      괜찮,   ,...      1\n","4     반갑습니다 소속 이름입니다   안녕하세요 제가 이번에 이벤트 쿠폰을 획득했는데요...      0\n","5     최선을 다하겠습니다 소속 이름입니다   수고하십니다 소속 서비스 센터죠   네 ...      0\n","6     연락 가능한 전화번호와 성함이 어떻게 되십니까   전화번호는전번이고요   이름은...      0\n","7   네 여보세요? 네 고객님  관리인 파워브로커 산업개발자입니다. 지금 일단 심사 결과...      1\n","8                                        사진이름이모티콘이모티콘      0\n","9   그런 것도 별로.. 제가 문자오면 이상한 건 안 열어보기 때문에 그럼 스팸멜이나 이...      1\n","10  우리금융이군요.  필요한 게 있으신가 해서 연락드렸어요. 필요하신 자본 있으세요. ...      1\n","11  그러면 제어울어울리다 재단이나 기금에 가서 뭐라고 얘기를 해야 개선하다,나요? 고객...      1\n","12  근데 이 회사 다니면 백퍼 자취각인데 응응 내가 집에서 응 220이면 감사합니다하고...      0\n","13  사진시스템 그러게?안왓나케이스? 잘먹어? 우린 칼국수먹으려고 함덕에 또바기알지? 거...      0\n","14    감사합니다 소속 이름입니다 무엇을 도와드릴까요   예 상품을 좀 사려고요   가...      0\n","15  그러면 저희 쪽에서 협조수사로 진행을 해드릴게요. 두 가지가 있어요. 수도권 쪽에서...      1\n","16  그럼 머가 더 데일리해? 이쁘거나 손이 잘사는 디쟌 먼가 버클이 무게감이 있으니까 ...      0\n","17  개고 쌓고 아 근데 원룸옷장이 내 방 옷장보다 컸어서 화가난다 착착착 헉 그건좀 슬...      0\n","18  안녕하세요.  컨설팅에서 전화 드렸습니다. 혹시 고금리로 대출 쓰고 계시면 은행권에...      1\n","19  그러면 제가 재단이나 기금에 가서 뭐라고 얘기를 해야 되나요? 고객님 먼저 진행을 ...      1\n","20  여보세요? 어떤 부분이요? 지금 이제 씨가 황미연씨 사건에 연로가 되어있기 때문에 ...      1\n","21  어? 네네 아 예 고객님 저 그 담당자입니다 아 조금 전에 계속 이제 통화 중이고 ...      1\n","22  아 마따 아! 나 중기청승인나서 20일자로 대출 기다리는 중인데, 그날도 부동산 가...      0\n","23  나 근데 책 짜름 무거워서 조각조각 분철 할 데가 없고...어차피새것도 아니라서 굿...      0\n","24  여보세요? 네 여보세요? 분실당하거나 도난당한 적은 없습니까? 네 그럼 혹시 지난 ...      1\n","25  전기버스 엿어 매의 눈이겟다 레알 그 아 전기버스 알아 좋아보이긴해 새거느낌 오 맞...      0\n","26   오오 맞춤 좋아요오 버스타고 전주가는거보다 여보에게 특명을 줄게 이게 훨씬 더 좋...      0\n","27    안녕하세요 소속 고객만족센터 이름입니다   안녕하세요 저는 이름입니다   네 이...      0\n","28  세제 저기 넣음돼낭 사진 안왔음 어디? 사진이안감 엉 안왔띠 사진 우씨 넣다가 쏟음...      0\n","29  몇가지 확인할 상황에 있어서 연락드리셨는데요. 지금 통화가 가능하겠습니까? 네. 단...      1"],"text/html":["\n","  <div id=\"df-e561980e-f7d6-45b9-bac0-de7a94d6473c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>반갑습니다 소속 상담사 이름입니다 무엇을 도와드릴까요   일주일 동안 계속 인터...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>네 본인 혹시 에 거주하는 42세 남성 김춘철이라고 아시는 분이십니까? 아 모르는데...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>걱정 안 하셔도 되고 신용등급 하락이라는 건 14일 이내에 채무 계약 처리로 상황처...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>아 예 수고하십니다. 서울지검 김수사관이에요. 지금 통화 좀      괜찮,   ,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>반갑습니다 소속 이름입니다   안녕하세요 제가 이번에 이벤트 쿠폰을 획득했는데요...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>최선을 다하겠습니다 소속 이름입니다   수고하십니다 소속 서비스 센터죠   네 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>연락 가능한 전화번호와 성함이 어떻게 되십니까   전화번호는전번이고요   이름은...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>네 여보세요? 네 고객님  관리인 파워브로커 산업개발자입니다. 지금 일단 심사 결과...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>사진이름이모티콘이모티콘</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>그런 것도 별로.. 제가 문자오면 이상한 건 안 열어보기 때문에 그럼 스팸멜이나 이...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>우리금융이군요.  필요한 게 있으신가 해서 연락드렸어요. 필요하신 자본 있으세요. ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>그러면 제어울어울리다 재단이나 기금에 가서 뭐라고 얘기를 해야 개선하다,나요? 고객...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>근데 이 회사 다니면 백퍼 자취각인데 응응 내가 집에서 응 220이면 감사합니다하고...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>사진시스템 그러게?안왓나케이스? 잘먹어? 우린 칼국수먹으려고 함덕에 또바기알지? 거...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>감사합니다 소속 이름입니다 무엇을 도와드릴까요   예 상품을 좀 사려고요   가...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>그러면 저희 쪽에서 협조수사로 진행을 해드릴게요. 두 가지가 있어요. 수도권 쪽에서...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>그럼 머가 더 데일리해? 이쁘거나 손이 잘사는 디쟌 먼가 버클이 무게감이 있으니까 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>개고 쌓고 아 근데 원룸옷장이 내 방 옷장보다 컸어서 화가난다 착착착 헉 그건좀 슬...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>안녕하세요.  컨설팅에서 전화 드렸습니다. 혹시 고금리로 대출 쓰고 계시면 은행권에...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>그러면 제가 재단이나 기금에 가서 뭐라고 얘기를 해야 되나요? 고객님 먼저 진행을 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>여보세요? 어떤 부분이요? 지금 이제 씨가 황미연씨 사건에 연로가 되어있기 때문에 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>어? 네네 아 예 고객님 저 그 담당자입니다 아 조금 전에 계속 이제 통화 중이고 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>아 마따 아! 나 중기청승인나서 20일자로 대출 기다리는 중인데, 그날도 부동산 가...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>나 근데 책 짜름 무거워서 조각조각 분철 할 데가 없고...어차피새것도 아니라서 굿...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>여보세요? 네 여보세요? 분실당하거나 도난당한 적은 없습니까? 네 그럼 혹시 지난 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>전기버스 엿어 매의 눈이겟다 레알 그 아 전기버스 알아 좋아보이긴해 새거느낌 오 맞...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>오오 맞춤 좋아요오 버스타고 전주가는거보다 여보에게 특명을 줄게 이게 훨씬 더 좋...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>안녕하세요 소속 고객만족센터 이름입니다   안녕하세요 저는 이름입니다   네 이...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>세제 저기 넣음돼낭 사진 안왔음 어디? 사진이안감 엉 안왔띠 사진 우씨 넣다가 쏟음...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>몇가지 확인할 상황에 있어서 연락드리셨는데요. 지금 통화가 가능하겠습니까? 네. 단...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e561980e-f7d6-45b9-bac0-de7a94d6473c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e561980e-f7d6-45b9-bac0-de7a94d6473c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e561980e-f7d6-45b9-bac0-de7a94d6473c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8d15c333-2991-46ab-aa94-50472f369078\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d15c333-2991-46ab-aa94-50472f369078')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8d15c333-2991-46ab-aa94-50472f369078 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification, AdamW\n","from tqdm import tqdm  # tqdm을 import합니다.\n","\n","# GPU 사용 설정 (선택사항)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"/content/drive/MyDrive/intergrated_unbalan4.csv\")\n","\n","# 텍스트와 라벨 컬럼 분리\n","texts = data['text'].tolist()\n","labels = data['label'].tolist()\n","\n","# 훈련 데이터와 검증 데이터 분리\n","train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n","\n","# Electra 토크나이저 불러오기\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n","\n","# 토큰화 및 패딩\n","max_length = 128  # 적절한 시퀀스 길이 설정\n","# tqdm을 사용하여 인코딩 과정을 표시합니다.\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n","\n","# PyTorch 데이터셋 생성\n","train_dataset = TensorDataset(train_encodings['input_ids'],\n","                              train_encodings['attention_mask'],\n","                              torch.tensor(train_labels))\n","val_dataset = TensorDataset(val_encodings['input_ids'],\n","                            val_encodings['attention_mask'],\n","                            torch.tensor(val_labels))\n","\n","# 데이터 로더 생성\n","batch_size = 16  # 적절한 배치 크기 설정\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# KoELECTRA 모델 불러오기\n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-discriminator\", num_labels=2)\n","model.to(device)\n","\n","# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","# 학습\n","num_epochs = 5  # 적절한 에폭 수 설정\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        input_ids, attention_mask, labels = batch\n","        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 검증\n","    model.eval()\n","    val_loss = 0\n","    correct_predictions = 0\n","    total_predictions = 0\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            input_ids, attention_mask, labels = batch\n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            val_loss += outputs.loss.item()\n","\n","            predicted_labels = outputs.logits.argmax(dim=1)\n","            correct_predictions += (predicted_labels == labels).sum().item()\n","            total_predictions += labels.size(0)\n","\n","    val_accuracy = correct_predictions / total_predictions\n","    avg_val_loss = val_loss / len(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}: Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n","\n","print(\"Training complete!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQz5toP5CyiT","executionInfo":{"status":"ok","timestamp":1692875084836,"user_tz":-540,"elapsed":2010564,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"284b29ed-cb53-4b69-8672-20f751c1f9d7"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","Epoch 1/5 - Training: 100%|██████████| 1000/1000 [06:04<00:00,  2.75it/s]\n","Epoch 1/5 - Validation: 100%|██████████| 250/250 [00:32<00:00,  7.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5: Val Loss: 0.0026, Val Acc: 0.9992\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Training: 100%|██████████| 1000/1000 [06:05<00:00,  2.74it/s]\n","Epoch 2/5 - Validation: 100%|██████████| 250/250 [00:32<00:00,  7.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/5: Val Loss: 0.0000, Val Acc: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Training: 100%|██████████| 1000/1000 [06:05<00:00,  2.74it/s]\n","Epoch 3/5 - Validation: 100%|██████████| 250/250 [00:32<00:00,  7.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/5: Val Loss: 0.0000, Val Acc: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Training: 100%|██████████| 1000/1000 [06:05<00:00,  2.73it/s]\n","Epoch 4/5 - Validation: 100%|██████████| 250/250 [00:32<00:00,  7.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/5: Val Loss: 0.0000, Val Acc: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Training: 100%|██████████| 1000/1000 [06:04<00:00,  2.74it/s]\n","Epoch 5/5 - Validation: 100%|██████████| 250/250 [00:32<00:00,  7.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/5: Val Loss: 0.0000, Val Acc: 1.0000\n","Training complete!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import ElectraForSequenceClassification\n","\n","# 모델 저장 경로\n","model_path = \"/content/drive/MyDrive/finalvoice/Electra_intergrated_unbalan4\"\n","\n","# 모델 저장\n","model.save_pretrained(model_path)\n"],"metadata":{"id":"1YoIK70pOMsD","executionInfo":{"status":"ok","timestamp":1692875226421,"user_tz":-540,"elapsed":1451,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["!pip install gradio torch transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IN9CWlMkNzXf","executionInfo":{"status":"ok","timestamp":1692875156485,"user_tz":-540,"elapsed":11448,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"08e2f3fd-95c6-4f6a-ac8a-66c857e26541"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.101.1-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.5.0 (from gradio)\n","  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.16.4)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.7.1)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.6.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n","  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.9.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.3)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=05a37bb3a904eade4e4b2db5ed44dbb68e569538776014d14c8b96d942f14d76\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n","Successfully installed aiofiles-23.2.1 fastapi-0.101.1 ffmpy-0.3.1 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 orjson-3.9.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uvicorn-0.23.2 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","import torch\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","\n","# KoELECTRA 모델 및 토크나이저 불러오기\n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-discriminator\", num_labels=2)\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n","\n","# 예측 함수 정의\n","def predict(text):\n","    # 입력 텍스트를 토큰화하여 인코딩\n","    encoding = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n","\n","    # 모델 예측 수행\n","    with torch.no_grad():\n","        outputs = model(**encoding)\n","        logits = outputs.logits\n","        probabilities = torch.softmax(logits, dim=1).tolist()[0]  # 확률값 계산\n","\n","    return {str(label): prob for label, prob in enumerate(probabilities)}\n","\n","# Gradio 인터페이스 정의\n","iface = gr.Interface(fn=predict, inputs=\"text\", outputs=gr.outputs.JSON())\n","iface.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"id":"ZnisM0H1N0dL","executionInfo":{"status":"ok","timestamp":1692875320079,"user_tz":-540,"elapsed":3133,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"c7beb16b-80b4-4518-8249-b4514f6edcb2"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","<ipython-input-93-2584397833fa>:23: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  iface = gr.Interface(fn=predict, inputs=\"text\", outputs=gr.outputs.JSON())\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","source":["### 임베딩 (총 1만건)"],"metadata":{"id":"rGLxW2arxKFV"}},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","\n","# KoBERT 토크나이저와 모델 로드\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","model = BertModel.from_pretrained('monologg/kobert')\n","\n","# 데이터 토큰화\n","texts = intergrated_unbalan2['text'].values\n","inputs = tokenizer(texts.tolist(), return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n","\n","# 데이터 임베딩\n","embeddings = []\n","for i in tqdm(range(inputs['input_ids'].shape[0])):\n","    with torch.no_grad():\n","        embed = model(input_ids=inputs['input_ids'][i].unsqueeze(0), attention_mask=inputs['attention_mask'][i].unsqueeze(0)).last_hidden_state.mean(dim=1).numpy()\n","        embeddings.append(embed)\n","embeddings = np.concatenate(embeddings, axis=0)\n","\n","print(embeddings.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsYYz2bqcbDs","executionInfo":{"status":"ok","timestamp":1692865142740,"user_tz":-540,"elapsed":1018535,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"123379c4-8e89-45ac-88bc-9340fde82a1a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 6980/6980 [16:50<00:00,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["(6980, 768)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### 임베딩 (총 2만건)"],"metadata":{"id":"yacj4jq0xN-H"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.utils import shuffle\n","\n","# 데이터 불러오기\n","label1_data = pd.read_csv(\"/content/drive/MyDrive/voise_antinoise_morphemes_refined_v3.csv\")\n","label0_data_1 = pd.read_csv(\"/content/drive/MyDrive/normalcall_original.csv\")\n","label0_data_2 = pd.read_csv(\"/content/drive/MyDrive/finaldataset/nofish.csv\")\n","label1_data[\"text\"] = label1_data[\"Translated_Sentence\"]\n","label1_data.drop(columns=['Translated_Sentence'], inplace=True)\n","label0_data_2[\"text\"] = label0_data_2[\"refined_text\"]\n","label0_data_2.drop(columns=['refined_text'], inplace=True)\n","\n","# 라벨 0 데이터 랜덤 추출\n","label0_data_1_sampled = label0_data_1.sample(n=5000, random_state=42)\n","label0_data_2_sampled = label0_data_2.sample(n=5000, random_state=42)\n","\n","# 라벨 부여\n","label1_data['label'] = 1\n","label0_data_1_sampled['label'] = 0\n","label0_data_2_sampled['label'] = 0\n","\n","# 데이터 병합\n","intergrated_unbalan3 = pd.concat([label1_data, label0_data_1_sampled, label0_data_2_sampled])\n","intergrated_unbalan3 = shuffle(intergrated_unbalan3, random_state=42).reset_index(drop=True)\n","\n","# 결과 확인\n","intergrated_unbalan3.head()\n","\n","from transformers import BertTokenizer, BertModel\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","\n","# KoBERT 토크나이저와 모델 로드\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","model = BertModel.from_pretrained('monologg/kobert')\n","\n","# 데이터 토큰화\n","texts = intergrated_unbalan3['text'].values\n","inputs = tokenizer(texts.tolist(), return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n","\n","# 데이터 임베딩\n","embeddings = []\n","for i in tqdm(range(inputs['input_ids'].shape[0])):\n","    with torch.no_grad():\n","        embed = model(input_ids=inputs['input_ids'][i].unsqueeze(0), attention_mask=inputs['attention_mask'][i].unsqueeze(0)).last_hidden_state.mean(dim=1).numpy()\n","        embeddings.append(embed)\n","embeddings = np.concatenate(embeddings, axis=0)\n","\n","print(embeddings.shape)\n","\n","# 임베딩 결과 저장\n","np.save(\"/content/drive/MyDrive/intergrated_unbalan3_embeddings.npy\", embeddings)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkhUIRxfqhgv","executionInfo":{"status":"ok","timestamp":1692867638365,"user_tz":-540,"elapsed":1743462,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"cc86f6ed-fedf-4e36-a32f-d5eb902d874c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 11980/11980 [28:50<00:00,  6.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(11980, 768)\n"]}]},{"cell_type":"markdown","source":["### 임베딩 후 SMOTE된 np기반 분류 레이어 커스텀 학습 진행 (1트)\n","\n"],"metadata":{"id":"4VQKe_Lecben"}},{"cell_type":"code","source":["import torch.nn as nn\n","from transformers import ElectraConfig, ElectraPreTrainedModel\n","\n","# ElectraClassificationHead는 transformers 라이브러리의 ElectraForSequenceClassification 모델 내에 정의된 클래스입니다.\n","# 이를 사용하기 위해서는 이 클래스를 별도로 가져와야 합니다.\n","\n","class ElectraClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n","\n","    def forward(self, features, **kwargs):\n","        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.out_proj(x)\n","        return x\n","\n","# ElectraForSequenceClassification 모델을 커스터마이징하여\n","# 임베딩 레이어를 건너뛰고 직접 입력된 임베딩 데이터를 분류 레이어로 전달합니다.\n","# 모델을 커스터마이징하여 이미 임베딩된 데이터를 바로 인코더에 전달하도록 수정하였습니다.\n","\n","import torch.nn as nn\n","from transformers import ElectraConfig, ElectraPreTrainedModel, ElectraModel\n","\n","class CustomElectraForSequenceClassification(ElectraPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.electra = ElectraModel(config)\n","        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n","        outputs = self.electra(input_ids=input_ids,\n","                               attention_mask=attention_mask,\n","                               token_type_ids=token_type_ids,\n","                               position_ids=position_ids,\n","                               head_mask=head_mask,\n","                               inputs_embeds=inputs_embeds)\n","        sequence_output = outputs[0]\n","        logits = self.classifier(sequence_output)\n","'''\n","# 이제 모델을 초기화하고 학습을 시작합니다.\n","model = CustomElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=2)\n","\n","# 나머지 코드는 이전과 동일합니다.\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from transformers import ElectraForSequenceClassification, Trainer, TrainingArguments\n","\n","# 저장된 데이터 로드\n","import numpy as np\n","X_resampled = np.load('/content/drive/MyDrive/X_resampled.npy')\n","y_resampled = np.load('/content/drive/MyDrive/y_resampled.npy')\n","\n","# 최대 길이를 512로 제한\n","MAX_LENGTH = 512\n","X_resampled = X_resampled[:, :MAX_LENGTH]\n","\n","# 데이터를 토큰화하는 과정 없이 바로 텐서로 변환\n","train_inputs = torch.tensor(X_resampled, dtype=torch.long)\n","train_labels = torch.tensor(y_resampled)\n","\n","# 데이터를 훈련 세트와 검증 세트로 분할\n","train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, test_size=0.1, random_state=42)\n","\n","from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, tensors):\n","        self.tensors = tensors\n","\n","    def __len__(self):\n","        return len(self.tensors[0])\n","\n","    def __getitem__(self, index):\n","        return {'inputs_embeds': self.tensors[0][index]}\n","\n","\n","# 데이터로더 생성\n","train_dataset = CustomDataset((train_inputs, train_labels))\n","val_dataset = CustomDataset((val_inputs, val_labels))\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n","val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=16)\n","\n","# 훈련 설정\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    do_train=True,\n","    do_eval=True,\n","    no_cuda=False,\n","    load_best_model_at_end=True,\n","    evaluation_strategy='steps'\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")\n","\n","# 학습 시작\n","trainer.train()\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"aOsnJ6WnyQHW","executionInfo":{"status":"ok","timestamp":1692867988014,"user_tz":-540,"elapsed":353,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"2e7df5e9-89bc-4491-8083-4aeb10dbd5aa"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# 이제 모델을 초기화하고 학습을 시작합니다.\\nmodel = CustomElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=2)\\n\\n# 나머지 코드는 이전과 동일합니다.\\n\\nimport torch\\nfrom torch.utils.data import TensorDataset, DataLoader\\nfrom sklearn.model_selection import train_test_split\\nfrom transformers import ElectraForSequenceClassification, Trainer, TrainingArguments\\n\\n# 저장된 데이터 로드\\nimport numpy as np\\nX_resampled = np.load('/content/drive/MyDrive/X_resampled.npy')\\ny_resampled = np.load('/content/drive/MyDrive/y_resampled.npy')\\n\\n# 최대 길이를 512로 제한\\nMAX_LENGTH = 512\\nX_resampled = X_resampled[:, :MAX_LENGTH]\\n\\n# 데이터를 토큰화하는 과정 없이 바로 텐서로 변환\\ntrain_inputs = torch.tensor(X_resampled, dtype=torch.long)\\ntrain_labels = torch.tensor(y_resampled)\\n\\n# 데이터를 훈련 세트와 검증 세트로 분할\\ntrain_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, test_size=0.1, random_state=42)\\n\\nfrom torch.utils.data import Dataset\\n\\nclass CustomDataset(Dataset):\\n    def __init__(self, tensors):\\n        self.tensors = tensors\\n\\n    def __len__(self):\\n        return len(self.tensors[0])\\n\\n    def __getitem__(self, index):\\n        return {'inputs_embeds': self.tensors[0][index]}\\n\\n\\n# 데이터로더 생성\\ntrain_dataset = CustomDataset((train_inputs, train_labels))\\nval_dataset = CustomDataset((val_inputs, val_labels))\\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\\nval_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=16)\\n\\n# 훈련 설정\\ntraining_args = TrainingArguments(\\n    output_dir='./results',\\n    num_train_epochs=3,\\n    per_device_train_batch_size=16,\\n    per_device_eval_batch_size=16,\\n    warmup_steps=500,\\n    weight_decay=0.01,\\n    logging_dir='./logs',\\n    logging_steps=100,\\n    do_train=True,\\n    do_eval=True,\\n    no_cuda=False,\\n    load_best_model_at_end=True,\\n    evaluation_strategy='steps'\\n)\\n\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=train_dataset,\\n    eval_dataset=val_dataset\\n)\\n\\n# 학습 시작\\ntrainer.train()\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["X_resampled.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkrLdB2upSY9","executionInfo":{"status":"ok","timestamp":1692852167940,"user_tz":-540,"elapsed":4,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"40c1e584-c45a-46b9-8984-b7215521d578"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(27662, 512)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["### 임베딩 후 SMOTE된 np기반 분류 레이어 커스텀 학습 진행 (2트)"],"metadata":{"id":"D9CXwcjvitCJ"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from imblearn.over_sampling import SMOTE\n","from transformers import ElectraForSequenceClassification, Trainer, TrainingArguments, ElectraTokenizer\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Custom Dataset 정의\n","class CustomDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data[0])\n","\n","    def __getitem__(self, idx):\n","        return (self.data[0][idx], self.data[1][idx])\n","\n","\n","# 라벨 데이터 로드\n","y_labels = intergrated_unbalan3['label'].values\n","\n","# SMOTE를 사용하여 오버샘플링\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(embeddings, y_labels)\n","\n","# 데이터를 학습 데이터와 검증 데이터로 분할\n","train_inputs, val_inputs, train_labels, val_labels = train_test_split(X_resampled, y_resampled, test_size=0.1, random_state=42)\n","\n","# 데이터로더 생성\n","train_dataset = CustomDataset((torch.tensor(train_inputs, dtype=torch.float32), torch.tensor(train_labels)))\n","val_dataset = CustomDataset((torch.tensor(val_inputs, dtype=torch.float32), torch.tensor(val_labels)))\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n","val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=16)\n","\n","# 모델 초기화 (이전에 정의한 CustomElectraForSequenceClassification 사용)\n","model = CustomElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=2)\n","\n","# 훈련 설정\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    do_train=True,\n","    do_eval=True,\n","    no_cuda=False,\n","    load_best_model_at_end=True,\n","    evaluation_strategy='steps'\n",")\n","from torch.nn.utils.rnn import pad_sequence\n","\n","def custom_data_collator(batch):\n","    input_ids = [item[0] for item in batch]\n","    labels = [item[1] for item in batch]\n","\n","    input_ids = torch.stack(input_ids)  # torch.stack()을 사용하여 텐서로 변환합니다.\n","    labels = torch.tensor(labels, dtype=torch.long)\n","\n","    return {\n","        'input_ids': input_ids,\n","        'labels': labels\n","    }\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=custom_data_collator  # custom_data_collator를 사용합니다.\n",")\n","\n","# 학습 시작\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"66VkBjA-hwGR","executionInfo":{"status":"error","timestamp":1692867995342,"user_tz":-540,"elapsed":2120,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"157bd04b-234b-4614-bfe1-7c60c9ac59b9"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of CustomElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-a977e29935dc>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2707\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-9e61c09ef10b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         outputs = self.electra(input_ids=input_ids,\n\u001b[0m\u001b[1;32m     41\u001b[0m                                \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [16, 768].  Tensor sizes: [1, 512]"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","sample_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","sample_batch = next(iter(sample_loader))\n","print(sample_batch[0].shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cWGX6XTzaN-","executionInfo":{"status":"ok","timestamp":1692868206496,"user_tz":-540,"elapsed":3,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"31929d7e-a193-44fa-815c-dc00ef971ad0"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 768])\n"]}]},{"cell_type":"markdown","source":["### 임베딩 후 SMOTE된 np기반 분류 레이어 커스텀 학습 진행: 그냥 kobert 로 하자..."],"metadata":{"id":"hDCcWigU0uvK"}},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","\n","# 데이터와 라벨 분리\n","X = embeddings\n","y = intergrated_unbalan3['label'].values\n","\n","# SMOTE를 사용하여 오버샘플링\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# 결과 확인\n","print(\"원본 데이터 라벨 분포:\", pd.Series(y).value_counts())\n","print(\"오버샘플링 후 데이터 라벨 분포:\", pd.Series(y_resampled).value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYO_Z6LV2JL5","executionInfo":{"status":"ok","timestamp":1692870825386,"user_tz":-540,"elapsed":450,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"3840e34b-aed4-4f36-c7f8-1f6668767a84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["원본 데이터 라벨 분포: 0    10000\n","1     1980\n","dtype: int64\n","오버샘플링 후 데이터 라벨 분포: 0    10000\n","1    10000\n","dtype: int64\n"]}]},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","from transformers import BertTokenizer, BertForMaskedLM  # BertForMaskedLM 모델 사용\n","import torch\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# 데이터와 라벨 분리\n","X = embeddings\n","y = intergrated_unbalan3['label'].values\n","\n","# SMOTE를 사용하여 오버샘플링\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# 오버샘플링된 임베딩 데이터를 텍스트 데이터로 역변환\n","reverse_tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","from transformers import BertLMHeadModel\n","\n","reverse_model = BertLMHeadModel.from_pretrained('monologg/kobert', is_decoder=True)\n","reverse_model.eval()\n","\n","reconstructed_texts = []\n","\n","for i in tqdm(range(X_resampled.shape[0])):\n","    with torch.no_grad():\n","        masked_input = torch.tensor(X_resampled[i]).reshape(1, -1)\n","        target_size = X_resampled.shape[1] + 10  # 목표 크기 설정\n","        tensor_size = masked_input.size(1)  # 현재 텐서 크기 확인\n","\n","        # 텐서 크기를 조정하여 일치시킴\n","        if tensor_size < target_size:\n","            padding = torch.zeros(1, target_size - tensor_size)\n","            masked_input = torch.cat((masked_input, padding), dim=1)\n","        elif tensor_size > target_size:\n","            masked_input = masked_input[:, :target_size]\n","\n","        # input_ids 생성\n","        input_ids = masked_input.new_full((1, target_size), reverse_tokenizer.mask_token_id)\n","        input_ids[0, :masked_input.size(1)] = masked_input\n","\n","        # 생성된 input_ids로 예측\n","        predicted_ids = reverse_model.generate(input_ids)\n","        decoded_text = reverse_tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n","        reconstructed_texts.append(decoded_text)\n","\n","\n","\n","# 역변환된 텍스트 데이터와 오버샘플링된 라벨을 합쳐 데이터프레임으로 만듦\n","oversampled_data = pd.DataFrame({'text': reconstructed_texts, 'label': y_resampled})\n","\n","# 결과 확인\n","print(oversampled_data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"lau38Dnz4xsZ","executionInfo":{"status":"error","timestamp":1692870849077,"user_tz":-540,"elapsed":2162,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"7a038c1d-da09-4e07-b3dc-eb2bdb5da59c"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertLMHeadModel were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0%|          | 0/20000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1262: UserWarning: Input length of input_ids is 778, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n","  warnings.warn(\n","  0%|          | 0/20000 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-b32e1941a809>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# 생성된 input_ids로 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpredicted_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdecoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mreconstructed_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY_SEARCH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m             \u001b[0;31m# 11. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1597\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2445\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1236\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (778) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 778].  Tensor sizes: [1, 512]"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import AdamW\n","\n","# 1. 오버샘플링된 데이터를 텐서로 변환 및 데이터 로더 생성\n","X_resampled_tensor = torch.tensor(X_resampled, dtype=torch.float)\n","y_resampled_tensor = torch.tensor(y_resampled, dtype=torch.long)\n","dataset = TensorDataset(X_resampled_tensor, y_resampled_tensor)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n","\n","# 2. 학습 함수 정의 및 학습 진행\n","\n","class KoBERTforClassification(torch.nn.Module):\n","    def __init__(self, num_classes):\n","        super(KoBERTforClassification, self).__init__()\n","        self.linear = torch.nn.Linear(768, num_classes)\n","\n","    def forward(self, input_features):\n","        pooled_output = input_features.mean(dim=1)  # 이 부분을 수정합니다.\n","        logits = self.linear(pooled_output)\n","        return logits\n","\n","\n","def train(model, dataloader, optimizer, loss_fn, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        optimizer.zero_grad()\n","        input_features, labels = batch\n","        input_features, labels = input_features.to(device), labels.to(device)\n","        logits = model(input_features)\n","        loss = loss_fn(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_loss = total_loss / len(dataloader)\n","    return avg_loss\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = KoBERTforClassification(num_classes=2).to(device)\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","epochs = 3\n","for epoch in range(epochs):\n","    print(f\"에폭 {epoch + 1}/{epochs}\")\n","    avg_loss = train(model, dataloader, optimizer, loss_fn, device)\n","    print(f\"평균 손실: {avg_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"MjWUc3oh3WWD","executionInfo":{"status":"error","timestamp":1692869275979,"user_tz":-540,"elapsed":351,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"694cbe34-66d6-42da-8e22-8308b6effbae"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["에폭 1/3\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-863a00e4db89>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"에폭 {epoch + 1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"평균 손실: {avg_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-863a00e4db89>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-863a00e4db89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 이 부분을 수정합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x16 and 768x2)"]}]}]}