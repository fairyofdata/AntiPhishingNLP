{"cells":[{"cell_type":"markdown","source":["##KoBERT"],"metadata":{"id":"Apj3r_VOFxqd"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSzCDGhUV1rJ","executionInfo":{"status":"ok","timestamp":1692730639867,"user_tz":-540,"elapsed":11130,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"7a56f7f7-504f-4b86-84a8-5100d8174689"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"]}]},{"cell_type":"code","source":["# 필요한 라이브러리\n","import torch\n","from torch import nn\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AdamW\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jhVUsYdlVZGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ND-nuPx_MU9e"},"outputs":[],"source":["# df_93이라는 데이터가 있다고 가정\n","df_93 = pd.read_csv(\"/content/drive/MyDrive/KorCCViD_v1.3_fullcleansed.csv\")\n","# 데이터를 학습 데이터와 테스트 데이터로 나눕니다.\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(df_93['Transcript'], df_93['Label'], test_size=0.2, random_state=42)\n","# KoBERT 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","# 데이터 토큰화\n","class KoBERTDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = list(texts)\n","        self.labels = list(labels)\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = str(self.texts[index])\n","        label = self.labels[index]\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            truncation=True\n","        )\n","\n","        return {\n","            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n","            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","# DataLoader 설정\n","BATCH_SIZE = 16\n","MAX_LEN = 128\n","train_data = KoBERTDataset(X_train.reset_index(drop=True), y_train.reset_index(drop=True), tokenizer, MAX_LEN)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_data = KoBERTDataset(X_test.reset_index(drop=True), y_test.reset_index(drop=True), tokenizer, MAX_LEN)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"]},{"cell_type":"code","source":["# 모델 정의\n","model = BertForSequenceClassification.from_pretrained('monologg/kobert', num_labels=2)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","# 학습 설정\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","epochs = 10\n","from tqdm.notebook import tqdm\n","\n","# 학습 진행\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    # tqdm을 train_loader에 적용\n","    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False)\n","    for batch_idx, batch in enumerate(progress_bar):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs[0]\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","        # 진행 상황 업데이트\n","        progress_bar.set_postfix({'loss': total_loss / (batch_idx + 1)})\n","\n","    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss/len(train_loader)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885,"referenced_widgets":["f0d095aad08946a78717e3828b7b4688","ccf3cc3071e343d48b639946160e991b","54d6fec6d26b47e985cb6219f73a9945","42d2393e8d9e4e5da0c10556421749d1","23bfc419629e40e18894e0d3efd70c6b","e8401a172e0842e2a0fbe2a56820f399","8d6ab25f612d4166a6d41db512b51f43","a120d47412de4469ba413f7ef97daf98","2565b626a6fd46b0aeb874037a741454","82e7b09e4a3042c08d902f50d1904cfb","9665e642a2704d618f55779ac6271d2c"]},"id":"wDC73rAsVeSp","executionInfo":{"status":"ok","timestamp":1692692647072,"user_tz":-540,"elapsed":8041,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"27a7f755-e84b-4345-cadf-a7837de8ebc4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d095aad08946a78717e3828b7b4688"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import torch\n","\n","# 기존의 테스트 코드\n","model.eval()\n","all_preds = []\n","all_labels = []\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(outputs[0], 1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u9QSpizYXahg","executionInfo":{"status":"ok","timestamp":1692693986165,"user_tz":-540,"elapsed":2766,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"8a025703-bf56-4711-895d-d66635423564"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["accuracy = accuracy_score(all_labels, all_preds)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","# 모델 저장하기\n","save_path = \"/content/drive/MyDrive/finalvoice/kobert_model\"\n","torch.save(model.state_dict(), save_path)\n","print(f\"모델이 {save_path}에 저장되었습니다.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIObXznNbFDe","executionInfo":{"status":"ok","timestamp":1692693987934,"user_tz":-540,"elapsed":1773,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"93aaceaa-a237-4075-d7bc-d3f46b4f2b34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 96.72%\n","모델이 /content/drive/MyDrive/finalvoice/kobert_model에 저장되었습니다.\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import torch.nn.functional as F\n","import gradio as gr\n","\n","# 저장된 모델 경로\n","model_path = \"/content/drive/MyDrive/finalvoice/kobert_model\"\n","\n","# KoBERT 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","\n","# 모델 구조 불러오기\n","model = BertForSequenceClassification.from_pretrained('monologg/kobert')\n","# 저장된 가중치 불러오기\n","model.load_state_dict(torch.load(model_path))\n","model.eval()\n","\n","def get_prediction_probabilities(text):\n","    # 텍스트를 토크나이징\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","\n","    # 예측\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","\n","    # 확률을 계산하기 위해 softmax 함수 사용\n","    probs = F.softmax(logits, dim=-1)\n","\n","    # 결과를 딕셔너리 형태로 반환\n","    results = {}\n","    for i, prob in enumerate(probs[0]):\n","        results[f\"라벨 {i}\"] = float(prob)\n","\n","    return results\n","\n","# gr.Interface를 사용하여 웹 인터페이스 구성\n","interface = gr.Interface(fn=get_prediction_probabilities,\n","                         inputs=\"text\",\n","                         outputs=\"label\",\n","                         live=True,\n","                         title=\"KoBERT 라벨 예측\",\n","                         description=\"입력된 텍스트의 라벨 예측 확률을 출력합니다.\")\n","interface.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"VwbJjcL5uYI5","executionInfo":{"status":"error","timestamp":1692730620604,"user_tz":-540,"elapsed":4456,"user":{"displayName":"hufs_1jo","userId":"13927265952478603851"}},"outputId":"f018bfc6-d111-4ed7-e877-104339e5092c"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-46383b62009c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[],"metadata":{"id":"tDY5iiEBm0Vv"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1pdI9cIgk2IXsWvrxvaDwGLdvfR7BxXXV","timestamp":1692691452614},{"file_id":"1cY7fqqzUghF1e4k4duNKuPKLg557SI45","timestamp":1692679428059}],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1pdI9cIgk2IXsWvrxvaDwGLdvfR7BxXXV","authorship_tag":"ABX9TyPnmM+fXUygdBujuRwcX+0Y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f0d095aad08946a78717e3828b7b4688":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccf3cc3071e343d48b639946160e991b","IPY_MODEL_54d6fec6d26b47e985cb6219f73a9945","IPY_MODEL_42d2393e8d9e4e5da0c10556421749d1"],"layout":"IPY_MODEL_23bfc419629e40e18894e0d3efd70c6b"}},"ccf3cc3071e343d48b639946160e991b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8401a172e0842e2a0fbe2a56820f399","placeholder":"​","style":"IPY_MODEL_8d6ab25f612d4166a6d41db512b51f43","value":"Downloading model.safetensors: 100%"}},"54d6fec6d26b47e985cb6219f73a9945":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a120d47412de4469ba413f7ef97daf98","max":368769812,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2565b626a6fd46b0aeb874037a741454","value":368769812}},"42d2393e8d9e4e5da0c10556421749d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82e7b09e4a3042c08d902f50d1904cfb","placeholder":"​","style":"IPY_MODEL_9665e642a2704d618f55779ac6271d2c","value":" 369M/369M [00:00&lt;00:00, 456MB/s]"}},"23bfc419629e40e18894e0d3efd70c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8401a172e0842e2a0fbe2a56820f399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d6ab25f612d4166a6d41db512b51f43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a120d47412de4469ba413f7ef97daf98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2565b626a6fd46b0aeb874037a741454":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82e7b09e4a3042c08d902f50d1904cfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9665e642a2704d618f55779ac6271d2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}